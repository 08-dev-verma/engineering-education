Generative Adversarial Networks (GANs) currently hold the state-of-the-art on most image generation tasks when measured by sample quality metrics such as FID, Inception Score, and Precision. However, they do have their drawbacks that make them difficult to scale and apply to new domains.
Diffusion models have been around for a while. But, for the first time, this class of models have been pushed to the point where the images they produce images of high-quality. They are a class of likelihood-based models which have recently been shown to produce high-quality images  while offering desirable properties such as distribution coverage, a stationary training objective, and easy scalability. Recently, the Diffusion Models Beat GANs on Image Synthesis. This research is discussed in this [paper](ttps://arxiv.org/abs/2105.05233) which will be the basis of our article discussion.

### Understand issues with GANs

### How diffusion models solve this issues.

### Implementing an example to demonstrate how the model can be used.

### Further reading
- [Diffusion Models Beat GANs on Image Synthesis](https://arxiv.org/abs/2105.05233)